{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8aFzBu7SfqJ",
        "outputId": "0519318e-af19-45eb-fc8e-06d0120fb66c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AAMRANET', 'AAMRATECH', 'ABB1STMF', 'ABBANK', 'ABBLPBOND', 'ACFL', 'ACI', 'ACIFORMULA', 'ACMELAB', 'ACMEPL', 'ACTIVEFINE', 'ADNTEL', 'ADVENT', 'AFCAGRO', 'AFTABAUTO', 'AGNISYSL', 'AGRANINS', 'AIBL1STIMF', 'AIBLPBOND', 'AIL', 'AL-HAJTEX', 'ALARABANK', 'ALIF', 'ALLTEX', 'AMANFEED', 'AMBEEPHA', 'AMCL(PRAN)', 'ANLIMAYARN', 'ANWARGALV', 'AOL', 'APEXFOODS', 'APEXFOOT', 'APEXSPINN', 'APEXTANRY', 'APOLOISPAT', 'APSCLBOND', 'ARAMIT', 'ARAMITCEM', 'ARGONDENIM', 'ASIAINS', 'ASIAPACINS', 'ATCSLGF', 'ATLASBANG', 'AZIZPIPES', 'BANGAS', 'BANKASIA', 'BARKAPOWER', 'BATASHOE', 'BATBC', 'BAYLEASING', 'BBS', 'BBSCABLES', 'BDAUTOCA', 'BDCOM', 'BDFINANCE', 'BDLAMPS', 'BDSERVICE', 'BDTHAI', 'BDTHAIFOOD', 'BDWELDING', 'BEACHHATCH', 'BEACONPHAR', 'BENGALWTL', 'BERGERPBL', 'BEXGSUKUK', 'BEXIMCO', 'BGIC', 'BIFC', 'BNICL', 'BPML', 'BPPL', 'BRACBANK', 'BSC', 'BSCCL', 'BSRMLTD', 'BSRMSTEEL', 'BXPHARMA', 'BXSYNTH', 'CAPMBDBLMF', 'CAPMIBBLMF', 'CBLPBOND', 'CENTRALINS', 'CENTRALPHL', 'CITYBANK', 'CITYGENINS', 'CLICL', 'CNATEX', 'CONFIDCEM', 'CONTININS', 'COPPERTECH', 'CROWNCEMNT', 'CRYSTALINS', 'CVOPRL', 'DACCADYE', 'DAFODILCOM', 'DBH', 'DBH1STMF', 'DBLPBOND', 'DEBARACEM', 'DEBBDLUGG', 'DEBBDWELD', 'DEBBDZIPP', 'DEBBXDENIM', 'DEBBXFISH', 'DEBBXKNI', 'DEBBXTEX', 'DELTALIFE', 'DELTASPINN', 'DESCO', 'DESHBANDHU', 'DGIC', 'DHAKABANK', 'DHAKAINS', 'DOMINAGE', 'DOREENPWR', 'DSHGARME', 'DSSL', 'DULAMIACOT', 'DUTCHBANGL', 'EASTERNINS', 'EASTLAND', 'EASTRNLUB', 'EBL', 'EBL1STMF', 'EBLNRBMF', 'ECABLES', 'EGEN', 'EHL', 'EIL', 'EMERALDOIL', 'ENVOYTEX', 'EPGL', 'ESQUIRENIT', 'ETL', 'EXIM1STMF', 'EXIMBANK', 'FAMILYTEX', 'FARCHEM', 'FAREASTFIN', 'FAREASTLIF', 'FASFIN', 'FBFIF', 'FEDERALINS', 'FEKDIL', 'FINEFOODS', 'FIRSTFIN', 'FIRSTSBANK', 'FORTUNE', 'FUWANGCER', 'FUWANGFOOD', 'GBBPOWER', 'GEMINISEA', 'GENEXIL', 'GENNEXT', 'GHAIL', 'GHCL', 'GIB', 'GLDNJMF', 'GLOBALINS', 'GOLDENSON', 'GP', 'GPHISPAT', 'GQBALLPEN', 'GRAMEENS2', 'GREENDELMF', 'GREENDELT', 'GSPFINANCE', 'HAKKANIPUL', 'HEIDELBCEM', 'HFL', 'HRTEX', 'HWAWELLTEX', 'IBBL2PBOND', 'IBBLPBOND', 'IBNSINA', 'IBP', 'ICB', 'ICB3RDNRB', 'ICBAGRANI1', 'ICBAMCL2ND', 'ICBEPMF1S1', 'ICBIBANK', 'ICBSONALI1', 'ICICL', 'IDLC', 'IFADAUTOS', 'IFIC', 'IFIC1STMF', 'IFILISLMF1', 'ILFSL', 'IMAMBUTTON', 'INDEXAGRO', 'INTECH', 'INTRACO', 'IPDC', 'ISLAMIBANK', 'ISLAMICFIN', 'ISLAMIINS', 'ISNLTD', 'ITC', 'JAMUNABANK', 'JAMUNAOIL', 'JANATAINS', 'JHRML', 'JMISMDL', 'JUTESPINN', 'KARNAPHULI', 'KAY&QUE', 'KBPPWBIL', 'KDSALTD', 'KEYACOSMET', 'KOHINOOR', 'KPCL', 'KPPL', 'KTL', 'LANKABAFIN', 'LEGACYFOOT', 'LHBL', 'LIBRAINFU', 'LINDEBD', 'LOVELLO', 'LRBDL', 'LRGLOBMF1', 'MAKSONSPIN', 'MALEKSPIN', 'MARICO', 'MATINSPINN', 'MBL1STMF', 'MEGCONMILK', 'MEGHNACEM', 'MEGHNAINS', 'MEGHNALIFE', 'MEGHNAPET', 'MERCANBANK', 'MERCINS', 'METROSPIN', 'MHSML', 'MIDASFIN', 'MIDLANDBNK', 'MIRACLEIND', 'MIRAKHTER', 'MITHUNKNIT', 'MJLBD', 'MLDYEING', 'MONNOAGML', 'MONNOCERA', 'MONNOFABR', 'MONOSPOOL', 'MPETROLEUM', 'MTB', 'NAHEEACP', 'NATLIFEINS', 'NAVANACNG', 'NAVANAPHAR', 'NBL', 'NCCBANK', 'NCCBLMF1', 'NEWLINE', 'NFML', 'NHFIL', 'NITOLINS', 'NORTHERN', 'NORTHRNINS', 'NPOLYMER', 'NRBCBANK', 'NTC', 'NTLTUBES', 'NURANI', 'OAL', 'OIMEX', 'OLYMPIC', 'ONEBANKLTD', 'ORIONINFU', 'ORIONPHARM', 'PADMALIFE', 'PADMAOIL', 'PAPERPROC', 'PARAMOUNT', 'PBLPBOND', 'PDL', 'PENINSULA', 'PEOPLESINS', 'PF1STMF', 'PHARMAID', 'PHENIXINS', 'PHOENIXFIN', 'PHPMF1', 'PIONEERINS', 'PLFSL', 'POPULAR1MF', 'POPULARLIF', 'POWERGRID', 'PRAGATIINS', 'PRAGATILIF', 'PREBPBOND', 'PREMIERBAN', 'PREMIERCEM', 'PREMIERLEA', 'PRIME1ICBA', 'PRIMEBANK', 'PRIMEFIN', 'PRIMEINSUR', 'PRIMELIFE', 'PRIMETEX', 'PROGRESLIF', 'PROVATIINS', 'PTL', 'PUBALIBANK', 'PURABIGEN', 'QUASEMIND', 'QUEENSOUTH', 'RAHIMAFOOD', 'RAHIMTEXT', 'RAKCERAMIC', 'RANFOUNDRY', 'RDFOOD', 'RECKITTBEN', 'REGENTTEX', 'RELIANCE1', 'RELIANCINS', 'RENATA', 'RENWICKJA', 'REPUBLIC', 'RINGSHINE', 'RNSPIN', 'ROBI', 'RSRMSTEEL', 'RUNNERAUTO', 'RUPALIBANK', 'RUPALIINS', 'RUPALILIFE', 'SAFKOSPINN', 'SAIFPOWER', 'SAIHAMCOT', 'SAIHAMTEX', 'SALAMCRST', 'SALVOCHEM', 'SAMATALETH', 'SAMORITA', 'SANDHANINS', 'SAPORTL', 'SAVAREFR', 'SBACBANK', 'SEAPEARL', 'SEMLFBSLGF', 'SEMLIBBLSF', 'SEMLLECMF', 'SHAHJABANK', 'SHASHADNIM', 'SHEPHERD', 'SHURWID', 'SHYAMPSUG', 'SIBL', 'SILCOPHL', 'SILVAPHL', 'SIMTEX', 'SINGERBD', 'SINOBANGLA', 'SJIBLPBOND', 'SKICL', 'SKTRIMS', 'SONALIANSH', 'SONALILIFE', 'SONALIPAPR', 'SONARBAINS', 'SONARGAON', 'SOUTHEASTB', 'SPCERAMICS', 'SPCL', 'SQUARETEXT', 'SQURPHARMA', 'SSSTEEL', 'STANCERAM', 'STANDARINS', 'STANDBANKL', 'STYLECRAFT', 'SUMITPOWER', 'SUNLIFEINS', 'TAKAFULINS', 'TALLUSPIN', 'TAMIJTEX', 'TILIL', 'TITASGAS', 'TOSRIFA', 'TRUSTB1MF', 'TRUSTBANK', 'TUNGHAI', 'UCB', 'UNILEVERCL', 'UNIONBANK', 'UNIONCAP', 'UNIONINS', 'UNIQUEHRL', 'UNITEDFIN', 'UNITEDINS', 'UPGDCL', 'USMANIAGL', 'UTTARABANK', 'UTTARAFIN', 'VAMLBDMF1', 'VAMLRBBF', 'VFSTDL', 'WALTONHIL', 'WATACHEM', 'WMSHIPYARD', 'YPL', 'ZAHEENSPIN', 'ZAHINTEX', 'ZEALBANGLA', '1JANATAMF', '1STPRIMFMF']\n",
            "    Company Code\n",
            "0       AAMRANET\n",
            "1      AAMRATECH\n",
            "2       ABB1STMF\n",
            "3         ABBANK\n",
            "4      ABBLPBOND\n",
            "..           ...\n",
            "406   ZAHEENSPIN\n",
            "407     ZAHINTEX\n",
            "408   ZEALBANGLA\n",
            "409    1JANATAMF\n",
            "410   1STPRIMFMF\n",
            "\n",
            "[411 rows x 1 columns]\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "An error occurred: list index out of range\n",
            "     Trading Code          Date  Sponsor/Director  Govt  Institute  Foreign  \\\n",
            "0        AAMRANET  Jun 30, 2022             33.04   0.0      28.73     0.00   \n",
            "1        AAMRANET  Apr 30, 2023             33.04   0.0      20.15     0.00   \n",
            "2        AAMRANET  May 31, 2023             33.04   0.0      21.69     0.00   \n",
            "3       AAMRATECH  Jun 30, 2022             30.01   0.0      27.96     0.00   \n",
            "4       AAMRATECH  Apr 30, 2023             30.01   0.0      35.34     0.00   \n",
            "...           ...           ...               ...   ...        ...      ...   \n",
            "1195    1JANATAMF  Apr 30, 2023             25.00   0.0      34.97     0.00   \n",
            "1196    1JANATAMF  May 31, 2023             25.00   0.0      34.94     0.00   \n",
            "1197   1STPRIMFMF  Dec 31, 2022              2.00   0.0      12.67     0.01   \n",
            "1198   1STPRIMFMF  Apr 30, 2023              2.00   0.0      12.61     0.01   \n",
            "1199   1STPRIMFMF  May 31, 2023              2.00   0.0      18.26     0.01   \n",
            "\n",
            "      Public  \n",
            "0      38.23  \n",
            "1      46.81  \n",
            "2      45.27  \n",
            "3      42.03  \n",
            "4      34.65  \n",
            "...      ...  \n",
            "1195   40.03  \n",
            "1196   40.06  \n",
            "1197   85.32  \n",
            "1198   85.38  \n",
            "1199   79.73  \n",
            "\n",
            "[1200 rows x 7 columns]\n",
            "                        Company Name Trading Code Scrip Code          Sector\n",
            "0             aamra networks limited     AAMRANET      22649       IT Sector\n",
            "1         aamra technologies limited    AAMRATECH      22647       IT Sector\n",
            "2            AB Bank 1st Mutual fund     ABB1STMF      12189    Mutual Funds\n",
            "3                    AB Bank Limited       ABBANK      11101            Bank\n",
            "4             AB Bank Perpetual Bond    ABBLPBOND      26013  Corporate Bond\n",
            "..                               ...          ...        ...             ...\n",
            "406          Zaheen Spinning Limited   ZAHEENSPIN      17467         Textile\n",
            "407      Zahintex Industries Limited     ZAHINTEX      17452         Textile\n",
            "408     Zeal Bangla Sugar Mills Ltd.   ZEALBANGLA      14266   Food & Allied\n",
            "409    First Janata Bank Mutual Fund    1JANATAMF      12178    Mutual Funds\n",
            "410  Prime Finance First Mutual Fund   1STPRIMFMF      12168    Mutual Funds\n",
            "\n",
            "[411 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def scrap_other_info(r,company,other_info_table):\n",
        "\n",
        "  try:\n",
        "    row = other_info_table.find_all('tr')[r]\n",
        "    cells = row.find_all('td')\n",
        "    date = cells[0].text.strip()\n",
        "    pattern = r'\\b\\w{3} \\d{2}, \\d{4}\\b'\n",
        "    # Search for the date pattern in the text\n",
        "    match = re.search(pattern, date)\n",
        "    if match:\n",
        "      date = match.group()\n",
        "      data = cells[1].text.strip()\n",
        "\n",
        "      #regex construction\n",
        "      sponsor_director_pattern = r'Sponsor/Director:\\s+([\\d.]+)'\n",
        "      govt_pattern = r'Govt:\\s+([\\d.]+)'\n",
        "      institute_pattern = r'Institute:\\s+([\\d.]+)'\n",
        "      foreign_pattern = r'Foreign:\\s+([\\d.]+)'\n",
        "      public_pattern = r'Public:\\s+([\\d.]+)'\n",
        "\n",
        "      # Find the matches using regex\n",
        "      sponsor_director_match = re.findall(sponsor_director_pattern, data)\n",
        "      govt_match = re.findall(govt_pattern, data)\n",
        "      institute_match = re.findall(institute_pattern, data)\n",
        "      foreign_match = re.findall(foreign_pattern, data)\n",
        "      public_match = re.findall(public_pattern, data)\n",
        "\n",
        "      # Extracing the values from the matches and convert them to float\n",
        "      sponsor_director_values = [float(value.strip()) for value in sponsor_director_match]\n",
        "      govt_values = [float(value.strip()) for value in govt_match]\n",
        "      institute_values = [float(value.strip()) for value in institute_match]\n",
        "      foreign_values = [float(value.strip()) for value in foreign_match]\n",
        "      public_values = [float(value.strip()) for value in public_match]\n",
        "      List = [company,date,*sponsor_director_values,*govt_values,*institute_values,*foreign_values,*public_values]\n",
        "\n",
        "      return List\n",
        "\n",
        "  except Exception as e:\n",
        "    # Handle any other exceptions\n",
        "    print(\"An error occurred:\", str(e))\n",
        "url = \"https://www.dsebd.org/company_listing.php\"\n",
        "page = requests.get(url)\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "all_body_content = soup.find_all(\"div\", {\"class\": \"BodyContent\"})\n",
        "company_list = []\n",
        "for com in all_body_content:\n",
        "  code = com.find_all(\"a\")\n",
        "  for only_code in code:\n",
        "\n",
        "    company_list.append(only_code.text.strip())\n",
        "company_list = [x for x in company_list if not x.startswith(\"TB\")]\n",
        "company_list = [x for x in company_list if not x.startswith(\"More...\")]\n",
        "print(company_list)\n",
        "company_list_df = pd.DataFrame(company_list)\n",
        "company_list_df = company_list_df.rename(columns={0: 'Company Code'})\n",
        "print(company_list_df)\n",
        "company_details = []\n",
        "other_info = []\n",
        "for company in company_list:\n",
        "  row_data = []\n",
        "  baseurl = \"https://www.dsebd.org/displayCompany.php?name=\"+company\n",
        "\n",
        "  page = requests.get(baseurl)\n",
        "\n",
        "  soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "  #finding company names under h2 header of class BodyHead\n",
        "\n",
        "  companyname_header = soup.find('h2', {'class': 'BodyHead'})\n",
        "\n",
        "\n",
        "  com_name = companyname_header.text.strip()[companyname_header.text.strip().find(\": \") + len(\": \"):]\n",
        "  row_data.append(com_name)\n",
        "\n",
        "\n",
        "  com_table = soup.find('table', {'class': 'shares-table'})\n",
        "  for row in com_table.find_all('tr'):\n",
        "    for cell in row.find_all(['th']):\n",
        "        index = cell.text.strip().find(\": \")\n",
        "        substring = cell.text.strip()[index + len(\": \"):]\n",
        "        row_data.append(substring)\n",
        "  tables = soup.find_all('div', {'class': 'table-responsive'})\n",
        "  sector_table_info = tables[2]\n",
        "  r = sector_table_info.find_all('tr')[3]\n",
        "  cells = r.find_all('td')\n",
        "  sector = cells[1].text.strip()\n",
        "  row_data.append(sector)\n",
        "  company_details.append(row_data)\n",
        " #extracting other info\n",
        "\n",
        "  other_info_table = tables[9]\n",
        "  for num in [3, 5, 7]:\n",
        "      row = []\n",
        "      l = scrap_other_info(num,company,other_info_table)\n",
        "      other_info.append(l) #adding the data\n",
        "\n",
        "other_info = [value for value in filter(None, other_info)]\n",
        "company_info_df = pd.DataFrame(other_info,columns =['Trading Code', 'Date','Sponsor/Director','Govt','Institute','Foreign','Public']) #creating df\n",
        "\n",
        "# print(company_info_df)\n",
        "#df to csv\n",
        "file_path = '/content/holdings.csv'\n",
        "company_info_df.to_csv(file_path, index=False)\n",
        "company_details_df = pd.DataFrame(company_details, columns =['Company Name', 'Trading Code','Scrip Code','Sector'])\n",
        "\n",
        "print(company_details_df)\n",
        "file_path = '/content/companies.csv'\n",
        "company_details_df.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "headers = [\"company_ID\", \"company_name\", \"scrip_code\", \"trading_code\", \"sector\", \"url\", \"address\"]\n",
        "df = pd.DataFrame(columns=headers)\n",
        "\n",
        "url = \"https://www.dsebd.org/company_listing.php\"\n",
        "\n",
        "response = requests.get(url) # Send a GET request to the website\n",
        "\n",
        "\n",
        "soup = BeautifulSoup(response.content, \"html.parser\") #beautifulsoup object created\n",
        "\n",
        "# Find the HTML elements that contain the company code\n",
        "results = soup.find_all(\"div\", {\"class\" : \"BodyContent\"})\n",
        "trading_code = soup.find_all(\"a\", {\"class\" : \"ab1\"})\n",
        "t_code= []\n",
        "for result in results: #iterate and get trading codes\n",
        "    code = result.find_all(\"a\")\n",
        "    for getcode in code:\n",
        "        t_code.append(getcode.text.strip()) #appending the value that we got into the emply list\n",
        "        print(getcode.text.strip())"
      ],
      "metadata": {
        "id": "iekTX9RvWB8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "address_list=[]\n",
        "for result in results:\n",
        "  code = result.find_all(\"a\")\n",
        "  for name in code:\n",
        "    page1 = requests.get(\"https://dsebd.org/displayCompany.php?name=\" + name.text.strip())\n",
        "    soup = BeautifulSoup(page1.content, 'html.parser')\n",
        "    sector = soup.find('td', string='Web Address')\n",
        "    category = sector.find_next_siblings('td')\n",
        "    for td in category:\n",
        "              address = td.text.strip()\n",
        "              if address:\n",
        "                  address_list.append(address)\n",
        "              else:\n",
        "                  address_list.append(None)\n",
        "              print(address)"
      ],
      "metadata": {
        "id": "Msow_TcVVSzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_list=[]\n",
        "for result in results:\n",
        "  code = result.find_all(\"a\")\n",
        "  for name in code:\n",
        "    p = ('https://dsebd.org/displayCompany.php?name=' + name.text.strip())\n",
        "    url_list.append(p)\n",
        "# print(url_list)\n"
      ],
      "metadata": {
        "id": "i--IoLRLVUJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 1: Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('companies.csv')\n",
        "\n",
        "# Step 2: Modify the DataFrame by inserting the desired column\n",
        "new_column = ['url', 'address']  # Example column values\n",
        "df['url'] = url_list\n",
        "df['address'] = address_list\n",
        "df['new_column_name'] = new_column\n",
        "\n",
        "# Step 3: Save the modified DataFrame back to the CSV file\n",
        "df.to_csv('companies.csv', index=False)\n"
      ],
      "metadata": {
        "id": "2f7S7a1KXPNc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}